# 多模态相关模型

![image.png](%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9B%B8%E5%85%B3%E6%A8%A1%E5%9E%8B%20244814b57550480b8e15cbfd3371463b/image.png)

<aside>
💡 https://blog.csdn.net/qq_40168949/article/details/130374733

</aside>

![Untitled](%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9B%B8%E5%85%B3%E6%A8%A1%E5%9E%8B%20244814b57550480b8e15cbfd3371463b/Untitled.png)

https://zhuanlan.zhihu.com/p/653902791

# 多模态处理相关知识点：

1. **UNITER两段式训练任务：https://www.sohu.com/a/381020193_610522**
    1. 一种多模态的预训练方法，包括很多种不同的文本-图像对的预训练任务。
        
        ![截屏2024-08-06 10.48.42.png](%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9B%B8%E5%85%B3%E6%A8%A1%E5%9E%8B%20244814b57550480b8e15cbfd3371463b/%25E6%2588%25AA%25E5%25B1%258F2024-08-06_10.48.42.png)
        
2. LXMERT：跨模态的双流模型，使用了encoder-based的cross- attention，图像的“PE”用region
3. ViLBert：
4. Clip：

# ViLT

[多模态—ViLT：Vision-and-Language Transformer Without Convolution or Region Supervision](https://bytedance.larkoffice.com/wiki/wikcnvrv0tNY7aAuBk9H4MKKOne)

![截屏2024-08-01 10.58.18.png](%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9B%B8%E5%85%B3%E6%A8%A1%E5%9E%8B%20244814b57550480b8e15cbfd3371463b/%25E6%2588%25AA%25E5%25B1%258F2024-08-01_10.58.18.png)

# ALBEF

三个任务：ITC（I、T）、ITM（I、T）、MLM（I、T‘）两次前向forward过程→ 多次前向forward导致训练速度慢

编码器：图像VIT、文本Bert（分为两个部分）

Tricks：使用align之前的对齐+MoCo同款计算contrastive loss 的方法

贡献：**Momentum distill**：筛选数据EMA

![截屏2024-07-31 11.21.09.png](%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9B%B8%E5%85%B3%E6%A8%A1%E5%9E%8B%20244814b57550480b8e15cbfd3371463b/%25E6%2588%25AA%25E5%25B1%258F2024-07-31_11.21.09.png)

<aside>
💡

由于ITC和MLM存在noise label的问题，引入EMA的方法，进行one-hot和distill model之间的平衡→用于处理可能存在的训练不稳定的问题。

</aside>

# VLMo

https://blog.csdn.net/lansebingxuan/article/details/131749829

![image.png](%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9B%B8%E5%85%B3%E6%A8%A1%E5%9E%8B%20244814b57550480b8e15cbfd3371463b/image%201.png)

![image.png](%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9B%B8%E5%85%B3%E6%A8%A1%E5%9E%8B%20244814b57550480b8e15cbfd3371463b/image%202.png)

# Blip

1. https://www.bilibili.com/video/BV1uT411q7ef/?spm_id_from=333.337.search-card.all.click&vd_source=6bca3a9fd4e97372edd86bd01e681ef0
2. https://blog.csdn.net/m0_51976564/article/details/134356373
    
    **MED 架构**
    
    ![截屏2024-07-29 16.30.27.png](%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9B%B8%E5%85%B3%E6%A8%A1%E5%9E%8B%20244814b57550480b8e15cbfd3371463b/%25E6%2588%25AA%25E5%25B1%258F2024-07-29_16.30.27.png)
    
    **CapFilt 机制：通过现有的精校过的数据进训练**Captioner 和 Filter，通过训练好的Captioner 和 Filter对网络中获取的不确定的数据进行筛选。
    
    先使用含有噪声的网络数据训练一遍 BLIP，再在 COCO 数据集上进行微调以训练 Captioner 和 Filter，然后使用 Filter 从原始网络文本和合成文本中删除嘈杂的字幕，得到干净的数据。最后再使用干净的数据训练一遍得到高性能的 BLIP。
    
    ![截屏2024-07-29 16.33.06.png](%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9B%B8%E5%85%B3%E6%A8%A1%E5%9E%8B%20244814b57550480b8e15cbfd3371463b/%25E6%2588%25AA%25E5%25B1%258F2024-07-29_16.33.06.png)
    

# Blip2

https://blog.csdn.net/m0_51976564/article/details/134389066?spm=1001.2014.3001.5502

https://blog.csdn.net/m0_37708614/article/details/134122314

![截屏2024-07-29 17.18.27.png](%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9B%B8%E5%85%B3%E6%A8%A1%E5%9E%8B%20244814b57550480b8e15cbfd3371463b/%25E6%2588%25AA%25E5%25B1%258F2024-07-29_17.18.27.png)

# RoBERTa

一句话：更大的Bert，抛弃了NSP los，动态masking

[https://blog.csdn.net/Decennie/article/details/120010025](https://blog.csdn.net/Decennie/article/details/120010025)

# LLaVA

（使用VIT和LLaMa手动构建一个LLaVa：）

[https://github.com/yuanzhoulvpi2017/zero_nlp/blob/main/train_llava/code03_build_model_show.ipynb](https://github.com/yuanzhoulvpi2017/zero_nlp/blob/main/train_llava/code03_build_model_show.ipynb)

一句话：使用预训练好的ViT、LLaMa，通过embedding的对齐，训练W。接下来通过拼接进行输入训练。

数据：通过Cations和Boxes + ChatGPT4 进行生成instructions

[https://zhuanlan.zhihu.com/p/653902791](https://zhuanlan.zhihu.com/p/653902791)

# BeiT v3

![image.png](%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9B%B8%E5%85%B3%E6%A8%A1%E5%9E%8B%20244814b57550480b8e15cbfd3371463b/image%203.png)