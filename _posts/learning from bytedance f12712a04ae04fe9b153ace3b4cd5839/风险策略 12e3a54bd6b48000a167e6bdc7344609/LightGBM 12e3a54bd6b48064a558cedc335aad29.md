# LightGBM

https://zhuanlan.zhihu.com/p/366952043

互联网领域的算法应用，通常背后都有海量的大数据。深度学习中一系列神经网络算法，都是以 mini-batch 的方式喂数据迭代训练的，总训练数据量不受内存限制。

但我们用到的机器学习算法，比如 GBDT （参考ShowMeAI文章[**GBDT详解**](https://www.showmeai.tech/article-detail/193)）在每一次迭代的时候，都需要遍历整个训练数据多次。

- 如果把整个训练数据一次性装进内存，会明显限制训练数据的大小。
- 如果不装进内存，反复地读写训练数据又会消耗非常大的时间。

面对**工业级海量的数据，普通的 GBDT 算法无法满足需求**。 LightGBM 提出的主要原因之一，就是为了解决上述大数据量级下的 GBDT 训练问题，以便工业实践中能支撑大数据量并保证效率。