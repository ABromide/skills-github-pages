# 自然语言处理知识点

1. AIGC 系列分享 1：提示工程[bytetech.info](https://bytetech.info/articles/7382431283365806117?click_from=article_detail_included#UNFxdek1EoxUQ5x4sfOljhOngIC)
2. Prompt-Tuning：深度解读一种新的微调范式 ： [bytetech.info](https://bytetech.info/articles/7382127872510525440?click_from=article_detail_included#doxcngkNG5BHqPxjfAfRyHh7SNg)

‣ 数据处理纬度的trick

1. bert类型的finetuning是通过添加[cls]之类的新参数，而prompt- tuning是通过添加新的prompt和[mask]到文本之中,让MLM模型继续预测mask中的文本。

1. COT相关：https://github.com/amazon-science/auto-cot/tree/main?tab=readme-ov-file
    1. 总结起来就只有个步骤：1. 进行实例输入的编写，比如提前写几个问题和对应的符合逻辑推理的解答，或者直接将‘let's think step by step’放在最后，让模型按照步骤输出结果。
    2. auto-cot则将这两个结合到一起搞了一通，用bert-encoder+类似KNN的方法进行聚类，选取topk个问题进行auto-cot的操作。https://arxiv.org/pdf/2210.03493
2. 自我一致性（self- consistency）
    
    ![截屏2024-08-06 10.44.46.png](%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%9F%A5%E8%AF%86%E7%82%B9%20948f0b8e5b6f47358f56b67e35cc438f/%25E6%2588%25AA%25E5%25B1%258F2024-08-06_10.44.46.png)
    
3. 链式提示、TOT
4. ICL：in-content-learning，给出上下文的提示，让大模型学习。比如告诉大模型一个例子，再让模型去回答问题 → 和 few-shot learning的区别，后者是直接提供具体的任务，而前者只是放在内容中让模型学习
5. Self-instruct :应该是自己通过instruct生成一堆新的instruct的input和output数据来，再把这些数据拿回来给自己进行训练，相当于自己的提示和数据集都自己造。
6. Evol-Instruct:使用depth和breadth两个纬度的prompt进行生成不一样的instruct，进行instruct的生成和接下来的训练。
7. Sft简易流程:
    1. Huggingface download models,preparing Json data
    2. Using peft or (llama-factory) to do finetune,then merge two parameters(LoRA and orignal weight) and using llama.cpp quantilize model ，get gguf data
    3. Using ollama to upload
8. RAG：[检索增强(RAG)的LLM生成技术](https://bytedance.larkoffice.com/docx/ZtnMdUSsQo4iGTxRZHTcpUkmnqb?bk_entity_id=enterprise_7234391867344093212)
    1. 原始RAG（Naive RAG）（低精度、幻觉、风格不一致）、高级RAG（Advanced RAG [towardsdatascience.com](https://towardsdatascience.com/advanced-retrieval-augmented-generation-from-theory-to-llamaindex-implementation-4de1464a9930)）和模块化RAG（Modular RAG）
        
        ![截屏2024-08-06 10.45.12.png](%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%9F%A5%E8%AF%86%E7%82%B9%20948f0b8e5b6f47358f56b67e35cc438f/%25E6%2588%25AA%25E5%25B1%258F2024-08-06_10.45.12.png)
        
9. RAG vs 微调
    1. 优化技术的差异：RAG类似于为模型提供教科书，使其能够根据特定查询检索信息。适用于模型需要回答特定查询或处理特定信息检索任务的场景。微调则类似于让学生通过广泛学习来内化知识，适用于模型需要复制特定结构、风格或格式的情况。
    2. 适用场景：
    3. RAG：适用于需要回答具体查询或特定信息检索任务的场景。
    4. 微调：适用于强调基础模型中的现有知识，修改或定制模型输出，为模型提供复杂指令的场景。
    5. 互补性：RAG和微调不是相互排斥的，而是可以相互补充，从不同层面增强模型的能力。在某些情况下，结合这两种技术可以实现最佳的模型性能。
10. instruction learning、prompt learning区别：

![image (1).png](%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%9F%A5%E8%AF%86%E7%82%B9%20948f0b8e5b6f47358f56b67e35cc438f/image_(1).png)

1. 模型幻觉[大模型「幻觉」，看这一篇就够了-51CTO.COM](https://www.51cto.com/article/773845.html)
    1. 事实性幻觉（Factuality Hallucination）是指模型生成的内容与可验证的现实世界事实不一致。
    2. 忠实性幻觉（Faithfulness Hallucination）则是指模型生成的内容与用户的指令或上下文不一致。
    3. why：
        1. 1. 数据 （位置接近性、共现统计数据和相关文档计数等等）
        2. 2.训练过程：预训练阶段（大模型学习通用表示并获取世界知识：模型的问题）、对齐阶段（微调大模型使其更好地与人类偏好一致RLHF）两个阶段产生问题。
        3. 3.推理过程：
    4. How to deal：知识编辑 and RAG
2. langchain：https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide/tree/main

可以将输出的链路变成一个chain进行输出，将思考过程也输出出来。在此基础上，（zapier）可以载入更多的api，如ducument、youtube等，（Chroma**/**pinecone）构建本地知识库。比如之前用来总结视频内容的机器人就是根据这个工作构建的。（Serpapi）用来接入Google的搜索功能。

https://bytetech.info/articles/7340959524720738367?from=lark_all_search#XU8bdW6bDo2e4xxM9JHc6xf6njd

1. ReAct：https://arxiv.org/abs/2210.03629
    1. [ReAct 框架的代码实现工作原理 - 大模型知识库|大模型训练|开箱即用的企业大模型应用平台|智能体开发|53AI](https://www.53ai.com/news/qianyanjishu/719.html)实现起来的原理很简单，实际上就是调用工具+使用模型续写能力。
2. Few-Shot Prompting: Few-Shot 指的是在 Prompt 中指定任务时附带一些例子，借此得到更优的模型输出。
3. MoE：[混合专家模型（MoE）介绍](https://bytedance.larkoffice.com/docx/DoMmd2zW5omWBAxXn0uc2mc4n9c?hideTemplate=true&lang=zh&onboarding=0&opendoc=1&opendocVersion=0.0.3&shwm=true#AEDwdyTKXoA2yAxB51ac8gVMnfb)
4. Prefix-Tuning
5. RoPE：[Llama2架构和计算流程](https://bytedance.larkoffice.com/docx/Zm4gd7g7boFZamxvm36cmwJ5nsn)[transformer位置编码-RoPE](https://bytedance.larkoffice.com/wiki/YvppwCqy4imVcxkTEAkcAzZZn3z)
6. 长文本&RAG：[大模型未来发展：RAG vs 长文本，谁更胜一筹？](https://m.huxiu.com/article/2921037.html)
    1. 对于客服、金融分析等场景，需要长文本进行上下文分析，如果是改为切片，会丢失上下文之间的依赖关系
    2. 长文本是一种智力能力。拥有一个更好的上下文窗口，可以更好地解决代码的相互依赖和逻辑性问题。RAG 更像是能力的边界。如果只使用上下文窗口，而没有好好利用 RAG 基于检索的方式，很难解决同一个代码工程在多个模块，或者在多个功能上的问题。
    3. 如果不能接受信息损失，需要在系统里面投入更高的 RAG 成本。
    4. 如果只是进行角色扮演，或者是给出一个笼统的回答，那么长文本比较合适。
7. RAG分块算法[bytetech.info](https://bytetech.info/articles/7374282820992106515?from=message_bot&sender_type=101&message_id=7392795677048340489&column=like#Qkc2dqJkfory2zxxW52cON2Tnec)
    1. 基于规则的切分方法：1. 固定大小 2.内容感知 3.规则递归（文章->标题->段落->句子，知道大小小于阈值）4.特定数据结构
    2. 基于语义聚类的切分方法
        
        基于嵌入的语义分块本质上是通过一个滑动窗口（combined_sentence ）来计算相似度。那些相邻并且满足阈值的句子会被归为一个分块。，其主要步骤如下：
        
        1. 文本嵌入：首先，文本被输入到一个embedding模型中（如OpenAI的Embedding Model），该模型将文本中的每个句子或段落转换成高维空间中的向量。这些向量代表了文本的语义特征。
        2. 语义分析：利用这些嵌入向量，可以通过计算向量之间的相似度来评估句子或段落之间的语义关系。如通过余弦相似度等度量，来确定哪些文本部分在内容上是相似的。
        3. 分块决策：基于预设的相似度阈值或其他标准，这些语义相近的文本段落被分组为一个块（chunk）。这个过程通常涉及到确定“断点”，即在哪里开始新的分块，以确保每个分块在语义上尽可能的独立和完整。
    3. 基于机器学习模型的方法（bert之类）
    4. 基于大模型的切分方法
8. 大模型推理速度瓶颈：https://zhuanlan.zhihu.com/p/621438653
    1. **瓶颈一：**由于token需要和前面所有的token进行attention计算，大模型通常需要处理很长的输入和输出，随着`seq_len`的增加，模型需要的计算的矩阵尺寸也越来越大。
    2. **瓶颈二：无法并发计算。**在生成阶段，每个token的生成都依赖前面所有的计算，只能一个一个token生成。
    
    总的来说，推理瓶颈就在于Attention的计算是一个 ****$$O(N^2)$$的操作且**无法并发**。下面所介绍的技术都是针对以上两个瓶颈进行优化。
    
    ![截屏2024-08-06 10.46.20.png](%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%9F%A5%E8%AF%86%E7%82%B9%20948f0b8e5b6f47358f56b67e35cc438f/%25E6%2588%25AA%25E5%25B1%258F2024-08-06_10.46.20.png)
    
    [cloud.tencent.com](https://cloud.tencent.com/developer/article/2180522) [FlashAttention：具有 IO 感知，快速且内存高效的新型注意力算法](https://www.high-flyer.cn/en/blog/flash_attn/)
    
9. FlashAttention : https://blog.csdn.net/qinduohao333/article/details/131449876
10. 涌现能力：https://bytedance.larkoffice.com/wiki/UtoMw70AjizXn0kbY0XceS9lnWe（in content learning  && CoT）
    
    > 涌现能力（Emergent Abilities）是指在复杂系统中，当系统达到一定的规模或复杂度时，会出现新的行为或特性，这些行为或特性在系统的更小或更简单的状态下并不存在。在人工智能（AI）和机器学习领域，特别是在大型语言模型（如GPT系列）中，涌现能力是一个重要概念。涌现能力通常是指：
    **1. 规模效应**：当模型增大到一定规模时，它可能会展示出原先小型模型所没有的能力。例如，一个大型语言模型可能会展现出更好的理解、推理和创造力，这在更小的模型中不那么明显或完全不存在。
    **2. 复杂交互**：在多层次、大规模的神经网络中，不同层和节点间的复杂交互可能产生新的行为模式，这些模式在更简单或浅层的网络中无法观察到。
    **3. 数据多样性**：随着训练数据的增加，模型可能开始学习和表现出更多样化的行为，这些行为是从大量丰富和多样化的数据中“学来”的。
    
    涌现能力的例子：
    **1. 自然语言理解**：在大型语言模型中，随着模型规模的增加，模型可能开始展示对复杂文本和语境的深层理解，这在小型模型中很难实现。
    **2. 问题解决能力**：更大的模型可能开始展示出解决复杂问题的能力，例如，在未经特定训练的情况下回答复杂问题或进行有效的推理。
    **3. 创造力**：在艺术和写作等领域，更大规模的模型可能展现出更高的创造性，生成更原创和有吸引力的作品。
    > 
    
    我们在以后训练模型的时候，可以考虑先***增加训练数据，降低模型参数量，把模型做小，先把模型参数利用充分，在这个基础上，再继续增加数据，并推大模型规模。***也即是说，目前看，我们先把模型做小，再把模型做大，看上去是可行的。
    
    为什么会出现这种情况：
    
    1. **任务的评价指标不够平滑：任务太hard。**
        
        ![截屏2024-07-26 17.07.32.png](%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%9F%A5%E8%AF%86%E7%82%B9%20948f0b8e5b6f47358f56b67e35cc438f/%25E6%2588%25AA%25E5%25B1%258F2024-07-26_17.07.32.png)
        

EMA：https://zhuanlan.zhihu.com/p/68748778

自定义Lora的位置：https://huggingface.co/docs/peft/main/en/developer_guides/custom_models

QLora：https://huggingface.co/blog/zh/4bit-transformers-bitsandbytes

SwiGLU：https://www.51cto.com/article/785650.html

Scaling Law: https://zhuanlan.zhihu.com/p/667489780

![截屏2024-08-27 11.21.25.png](%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%9F%A5%E8%AF%86%E7%82%B9%20948f0b8e5b6f47358f56b67e35cc438f/%25E6%2588%25AA%25E5%25B1%258F2024-08-27_11.21.25.png)

微调系列：

Qlora：https://blog.csdn.net/HERODING23/article/details/131584089

1. 4位浮点数（NF4），对于正态分布权重来说是理论最优。
2. 双量化，通过量化量化常数来减少平均内存占用。
3. 分页优化器，管理内存的峰值。

LongLora：使用了S2attention：分快+一半的attention head shift； 同时添加 可训练的嵌入和归一化层来实现上下文扩展。https://blog.csdn.net/weixin_57291105/article/details/133638777

attention系列：

MHA：

MQA：

GQA：

Sparse Attention

位置编码系列：

绝对位置编码：

相对位置编码：

旋转位置编码（RoPE）：

ALiBi（Attention with Linear Biases）：不像标准transformer那样，在embedding层添加位置编码，而是在softmax的结果后添加一个静态的不可学习的偏置项(说白了，就是数值固定

![image.png](%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%9F%A5%E8%AF%86%E7%82%B9%20948f0b8e5b6f47358f56b67e35cc438f/image.png)

位置插值（PI）：

[https://blog.csdn.net/v_JULY_v/article/details/134085503](https://blog.csdn.net/v_JULY_v/article/details/134085503)

https://blog.csdn.net/v_JULY_v/article/details/134085503

https://blog.csdn.net/v_JULY_v/article/details/135072211?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0-135072211-blog-136068939.235^v43^pc_blog_bottom_relevance_base1&spm=1001.2101.3001.4242.1&utm_relevant_index=3

![截屏2024-09-25 13.01.02.png](%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%9F%A5%E8%AF%86%E7%82%B9%20948f0b8e5b6f47358f56b67e35cc438f/%25E6%2588%25AA%25E5%25B1%258F2024-09-25_13.01.02.png)

YaRN位置编码：

[https://blog.csdn.net/qq_41739364/article/details/136068939](https://blog.csdn.net/qq_41739364/article/details/136068939)

模型：

llama：rope + gqa + rms_norm + swiglu

Qwenhttps://www.53ai.com/news/OpenSourceLLM/2024072306721.html[l](https://www.53ai.com/news/OpenSourceLLM/2024072306721.html)

• **Grouped Query Attention+Dual Chunk Attention with YARN+Long-Context Training**

7T tokens 数据集上预训练的

![截屏2024-09-25 20.48.02.png](%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%9F%A5%E8%AF%86%E7%82%B9%20948f0b8e5b6f47358f56b67e35cc438f/%25E6%2588%25AA%25E5%25B1%258F2024-09-25_20.48.02.png)

同时将 RoPE 的基频从 10000 修改为 1000000

Normalize：

BN：

LN：

RMS Normal：去掉减均值这一步

强化学习篇：

https://mp.weixin.qq.com/s/pE_sSlaGUfKNM9EaBLR-cg

Tokenizer：

wordPrice

BPE

RAG：

embedding：https://techdiylife.github.io/blog/blog.html?category1=c02&blogid=0047

如 何改动模型训练时使用的loss：继承transformer中的seqtoseq trainer中的compute loss这个函数

[https://github.com/huggingface/transformers/blob/main/examples/legacy/seq2seq/seq2seq_trainer.py#L79](https://github.com/huggingface/transformers/blob/main/examples/legacy/seq2seq/seq2seq_trainer.py#L79)

项目的难点：

1. 在行为大模型中，如何去构造数据集。同时如何保证模型学到的是对规则链路的理解而不是记忆上的复述
2. 其次是

https://zhuanlan.zhihu.com/p/673323386