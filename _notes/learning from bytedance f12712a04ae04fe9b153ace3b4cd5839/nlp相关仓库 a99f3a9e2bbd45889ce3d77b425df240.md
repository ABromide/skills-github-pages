# nlp相关仓库

[GitHub - Hannibal046/Awesome-LLM: Awesome-LLM: a curated list of Large Language Model](https://github.com/Hannibal046/Awesome-LLM)

[GitHub - huybery/Awesome-Code-LLM: 👨💻 An awesome and curated list of best code-LLM for research.](https://github.com/huybery/Awesome-Code-LLM)

https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide/tree/main

langchain：可以将输出的链路变成一个chain进行输出，将思考过程也输出出来。在此基础上，（zapier）可以载入更多的api，如ducument、youtube等，（Chroma**/**pinecone）构建本地知识库。比如之前用来总结视频内容的机器人就是根据这个工作构建的。（Serpapi）用来接入Google的搜索功能。

# Finetune Tools：

[GitHub - hiyouga/LLaMA-Factory: Unify Efficient Fine-Tuning of 100+ LLMs](https://github.com/hiyouga/LLaMA-Factory)

# SFT paper：

现有的大部分进行SFT的工作，都是通过构建一个合适的prompt/instruction去构建一些独有的提示方向/或者扩充数据量。这样的方法来进行用大模型的泛化能力来在提高某一个特殊任务上的可行性。

[https://arxiv.org/abs/2212.10560](https://arxiv.org/abs/2212.10560)【self-instruct】https://zhuanlan.zhihu.com/p/614916562

通过一个self- instruct的方法进行指令的生成。应该是自己通过instruct生成一堆新的instruct的input和output数据来，再把这些数据拿回来给自己进行训练，相当于自己的提示和数据集都自己造。https://github.com/yizhongw/self-instruct/tree/main

```
# 1. Generate instructions from the seed tasks
./scripts/generate_instructions.sh

# 2. Identify whether the instruction represents a classification task or not
./scripts/is_clf_or_not.sh

# 3. Generate instances for each instruction
./scripts/generate_instances.sh

# 4. Filtering, processing, and reformatting
./scripts/prepare_for_finetuning.sh

```

[https://arxiv.org/abs/2304.12244](https://arxiv.org/abs/2304.12244)**WizardLM**

[https://arxiv.org/abs/2304.03277](https://arxiv.org/abs/2304.03277)[https://arxiv.org/abs/2305.11206](https://arxiv.org/abs/2305.11206)[https://arxiv.org/abs/2305.14233](https://arxiv.org/abs/2305.14233)[https://arxiv.org/pdf/2306.02707](https://arxiv.org/pdf/2306.02707)[https://arxiv.org/abs/2308.06259](https://arxiv.org/abs/2308.06259)[https://arxiv.org/abs/2308.10792](https://arxiv.org/abs/2308.10792)[https://arxiv.org/pdf/2401.01335](https://arxiv.org/pdf/2401.01335)

1. Instruction Tuning for Large Language Models: A Survey

这种模式下的用来finetune的数据一般是

- a natural language text sequence to specify the task
- an optional input which provides supplementary information for context;
- an anticipated output based on the instruction and the input.」

# MoCo

https://www.cvmart.net/community/detail/5179#circle=on